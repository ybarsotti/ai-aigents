{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a9e93-ed6a-4c09-86eb-6d8eebef20cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "DATA_DIR=\"./data\"\n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc7d1a-9294-4bb7-a899-3e56673a473f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's first load the document\n",
    "import boto3\n",
    "import shutil\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from botocore.client import Config\n",
    "\n",
    "account_id = os.getenv('R2_ACCOUNT_ID')\n",
    "access_key = os.getenv('R2_ACCESS_KEY')\n",
    "secret_key = os.getenv('R2_SECRET_KEY')\n",
    "tmp_dir = \"./tmp/\"\n",
    "os.makedirs(os.path.dirname(tmp_dir), exist_ok=True)\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=f'https://{account_id}.r2.cloudflarestorage.com',\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='auto'\n",
    ")\n",
    "\n",
    "bucket_name = \"yuri-data\"\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    file_key = obj['Key']\n",
    "    file_extension = os.path.splitext(file_key)[1].lower()\n",
    "    \n",
    "    local_path = f\"{tmp_dir}{file_key}\"\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    \n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(response[\"Body\"].read())\n",
    "\n",
    "pdf_loader = DirectoryLoader(tmp_dir, glob='**/*.pdf', loader_cls=PyPDFLoader, loader_kwargs={'mode': 'single'})\n",
    "txt_loader = DirectoryLoader(tmp_dir, glob='**/*.txt', loader_cls=TextLoader)\n",
    "\n",
    "pdf_doc = pdf_loader.load()\n",
    "txt_docs = txt_loader.load()\n",
    "\n",
    "# Joining all docs since I have more than one type\n",
    "all_docs = pdf_doc + txt_docs\n",
    "\n",
    "# It's a good practice to break the text into smaller chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(all_docs)\n",
    "\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95029603-e644-49bf-acbe-706307a672ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embedding text and upload\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from uuid import uuid4\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "# )\n",
    "\n",
    "# model_dimension = 384 # all-MiniLM-L12-v2\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# model_dimension = 768 # Gemini 001\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "model_dimension = 1536  # text-embedding-3-small\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_KEY'), text_key=\"text\")\n",
    "\n",
    "index_name = \"yuri-data\"\n",
    "\n",
    "# Check if index was already created\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=model_dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        ) \n",
    "    )\n",
    "    \n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(split_docs))]\n",
    "vector_store.add_documents(documents=split_docs, ids=uuids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa939679-50ed-4133-94ea-6d774655f2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Init retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc4ead-290d-40f3-811c-3915be96022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain import hub\n",
    "\n",
    "system_instructions = ''\n",
    "with open(\"./llm_instructions/system_prompt.txt\", \"r\") as llm_instructions_f:\n",
    "    system_instructions = llm_instructions_f.read()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_instructions.strip(),\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=150,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "answer = retrieval_chain.invoke({\n",
    "    \"input\": \"How many years of experience does he have with Python?\"\n",
    "})\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
